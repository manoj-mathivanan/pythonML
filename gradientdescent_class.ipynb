{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1a779Nxt-a9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    return x[0]**2 + x[1]**2 + 4"
      ],
      "metadata": {
        "id": "jJZeZvh-uEjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_f(x):\n",
        "    return np.array([2*x[0], 2*x[1]])\n"
      ],
      "metadata": {
        "id": "9ZGBXs5TuEr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(f, grad_f, initial_guess, learning_rate, num_iterations):\n",
        "    x = np.array(initial_guess)\n",
        "    losses = [] #Keep track of the loss for plotting\n",
        "    for i in range(num_iterations):\n",
        "        loss = f(x)\n",
        "        losses.append(loss)\n",
        "        grad = grad_f(x)\n",
        "        x = x - learning_rate * grad\n",
        "        print(f\"Iteration {i+1}: x = {x}, f(x) = {f(x)}\")\n",
        "    return x, losses"
      ],
      "metadata": {
        "id": "G9TmPdRHuJdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "initial_guess = (3, 4)\n",
        "learning_rate = 0.1\n",
        "num_iterations = 100"
      ],
      "metadata": {
        "id": "vj0sk_cSuOzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimizing the function\n",
        "final_position, losses = gradient_descent(f, grad_f, initial_guess, learning_rate, num_iterations)"
      ],
      "metadata": {
        "id": "kzZVZFLsuT3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss curve\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(losses, marker='o')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WIjHfbH_vRsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
